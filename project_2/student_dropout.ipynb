{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 2: Student Dropout Classifier\n",
    "*by Anna Kohnen & Marco Aigner*\n",
    "\n",
    "This notebook, inspired by [Martins et al.](https://link.springer.com/chapter/10.1007/978-3-030-72657-7_16), demonstrates how to predict students' academic success using different machine-learning algorithms.\n",
    "\n",
    "---\n",
    "## Original Research\n",
    "- Paragraph on the most important points of Martins et al.\n",
    "    - Comparison of different ml-algorithms\n",
    "    - Comparison of different upsampling-methods\n",
    "    - K-Fold-CV\n",
    "    - Hyperparameter Tuning\n",
    "    - Results\n",
    "\n",
    "---\n",
    "## The Data\n",
    "The dataset contains data from students from the Polytechnic Institute of Portalegre. It explicitly only includes information known at the time of students' enrollment and comprises features related to their academic path as well as to demographical and social-economic information. There are both numerical and categorical features included in the dataset.\n",
    "\n",
    "<div class=\"alert alert-block alert-info\"> <b>Caution:</b> The categorical features are encoded as numbers.</div>\n",
    "\n",
    "---\n",
    "## The Tasks\n",
    "The project comprises 6 tasks, listed as follows:\n",
    "\n",
    "1. To analyze and explore the dataset. To perform data pre-processing and cleansing.\n",
    "2. To calculate and visualize the correlation of features among each other and with the labels. To discuss an interesting correlation\n",
    "3. To train (at least) four machine-learning algorithms: One probabilistic, one tree-based, one distance-based and one ensemble method each.\n",
    "4. To evaluate the models using k-fold cross-validation. To report accuracy, mean standard deviation and a confusion matrix per model. To discuss whether one model is significantly better than the others\n",
    "5. To pick two favorite models. To discuss which features were most relevant for the students' success. To discuss differences between the two models\n",
    "6. So export the best performing model as ONNX to compete against other models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Packages\n",
    "First, import the necessary packages :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Move all imports here\n",
    "# TODO: Only import the necessary modules to save space\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_NAME = 'train'\n",
    "DELIMITER = ',' # TODO: parse all files to use comma separation, then drop this\n",
    "\n",
    "dataframe = pd.read_csv(f'./data/{FILE_NAME}.csv', delimiter=DELIMITER)\n",
    "dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Exploring and Pre-Processing\n",
    "The dataframe's ``shape`` attribute provides a tuple with the number of rows and columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```pd.DataFrame.info()``` details the columns' dtypes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output verifies that **1.** there are 36 features and one target variable and **2.** that categorical features are numerically encoded."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1.1 Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize a new dataframe to save the pre-processed data to:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_data = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For convenience and readabiltiy, transform the column names into ```snake_case```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a list of new column names by replacing spaces and '/' with _ and removing the rest\n",
    "snake_case_columns = dataframe.columns.map(lambda x: x.lower().replace(' ', '_').replace('/','_').replace('(','').replace(')', '').replace('\\t', '').replace('\\'s','')).to_list()\n",
    "student_data = dataframe.rename(columns=dict(zip(dataframe.columns, snake_case_columns))) # apply the snake_case column names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fixe a typo in a column-name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_data.rename(columns={'nacionality':'nationality'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Categorical columns (known from the [documentation](https://archive.ics.uci.edu/dataset/697/predict+students+dropout+and+academic+success)) can be parsed to pandas' explicit ```categorical``` dtype:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manually create a list of categorical column names\n",
    "categorical_columns = ['marital_status', 'application_mode', 'application_order', 'course', 'daytime_evening_attendance', 'previous_qualification', 'nationality', 'mother_qualification', 'father_qualification', 'mother_occupation', 'father_occupation', 'displaced', 'educational_special_needs', 'debtor', 'tuition_fees_up_to_date', 'gender', 'scholarship_holder', 'international', 'target']\n",
    "\n",
    "# assign the categorical dtype to respective columns\n",
    "student_data[categorical_columns] = student_data[categorical_columns].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numerically encode the targets using a dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "student_data['target'] = label_encoder.fit_transform(student_data['target'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 General Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensure that no data is missing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_data.isnull().values.any() # True if at least a single entry is missing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensure that there are no duplicates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_data.duplicated().values.any() # True if at least a single entry exists twice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect random rows of the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_data.sample(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas' ``describe()``-method provides useful statistics on the numerical features. \n",
    "\n",
    "Notice, how the features' scales differ:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``describe()`` on categorical columns provides different statistics, such as the number of unique as well as the most frequent variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_data.describe(include=['category'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Numerical Features: Scaling\n",
    "Scale all numerical features to have zero mean and unit variance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer, make_column_selector as selector\n",
    "\n",
    "# new dataframe to store the scaled values\n",
    "student_data_scaled = student_data.copy()\n",
    "\n",
    "# select numerical columns by their dtype\n",
    "numerical_columns = student_data_scaled.select_dtypes(include=['int64', 'float64'])\n",
    "\n",
    "# initialize a standard scaler with default parameters\n",
    "standard_scaler = StandardScaler()\n",
    "\n",
    "# scale numerical columns\n",
    "scaled = standard_scaler.fit_transform(numerical_columns)\n",
    "\n",
    "# override scaled columns\n",
    "student_data_scaled[numerical_columns.columns] = scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice, how the features are more similar after scaling:\n",
    "\n",
    "(makes them more comparable for the models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_column_names = numerical_columns.columns.to_list()\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(15, 5), sharey=True)\n",
    "ax = ax.flatten()\n",
    "\n",
    "sns.boxplot(student_data[numerical_column_names], ax=ax[0])\n",
    "\n",
    "ax[0].set_xticks(numerical_column_names)\n",
    "ax[0].set_xticklabels(numerical_column_names, rotation=90)\n",
    "ax[0].set_ylabel('value')\n",
    "ax[0].set_title('Before')\n",
    "\n",
    "sns.boxplot(student_data_scaled[numerical_column_names], ax=ax[1])\n",
    "ax[1].set_xticks(numerical_column_names)\n",
    "ax[1].set_xticklabels(numerical_column_names, rotation=90)\n",
    "ax[1].set_title('After')\n",
    "\n",
    "plt.suptitle('scaling of numerical features')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Categorical Features: One-Hot-Encoding\n",
    "One-Hot-Encoding creates one column each for distinct values of numerically encoded categorical features so that the models can not accidentally learn ordinal relationships where there are none.\n",
    "\n",
    "<div class=\"alert alert-block alert-info\"> <b>Omitted: </b>One-Hot-Encoding has been omitted due to time-restrictions but would have been performed otherwise.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Target Variables: Unbalanced Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice, how the dataset is imbalanced, as the 'Graduate' class makes out 50 % of all the data. Such imbalance can lead models to favor the majority classes to achieve higher accuracies.\n",
    "\n",
    "The imbalance will be dealt with using upsampling-methods later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_distribution = student_data.value_counts(subset=student_data['target'], normalize=True)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "plot = sns.barplot(data=label_distribution, ax=ax)\n",
    "plot.set_xticks(range(0, len(label_distribution)))\n",
    "plot.set_xticklabels(list(label_encoder.classes_))\n",
    "plot.bar_label(plot.containers[0], fmt='{0:.2f}')\n",
    "ax.set_ylim(0, 1)\n",
    "ax.set_title('class imbalance')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Correlation Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Features With The Target\n",
    "Features with a very low correlation with the target likely do not provide that much relevant information and are therefore dropped. This allows to focus on highly correlated features instedad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlate each feature column with the target column\n",
    "corr_feature_target = student_data_scaled.corrwith(other=student_data_scaled['target'], axis='index', drop=False, method='spearman')\n",
    "\n",
    "# print the sorted correlations\n",
    "corr_feature_target.sort_values(ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general, values closer to 0 indicate a low influence on the target variable, values closer to -1/+1 indicate a higher influence.\n",
    "\n",
    "Drop all features below with a small correlation below a pre-defined threshhold:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop all features with a correlation below 5 %\n",
    "CORRELATION_TRESHHOLD= 0.05 \n",
    "\n",
    "# apply the threshhold on the Series\n",
    "corr_feature_target_threshhold = corr_feature_target[abs(corr_feature_target) >= CORRELATION_TRESHHOLD]\n",
    "\n",
    "# print the remaining features\n",
    "corr_feature_target_threshhold_sorted = corr_feature_target_threshhold.sort_values(ascending=True)\n",
    "\n",
    "corr_feature_target_threshhold_sorted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how the number of features shrinked from 36 to 21.\n",
    "\n",
    "Plot the feature's correlation with the target:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20,5))\n",
    "\n",
    "ax = sns.barplot(corr_feature_target_threshhold_sorted)\n",
    "ax.set_xticks(range(0, len(corr_feature_target_threshhold_sorted)))\n",
    "ax.set_xticklabels(corr_feature_target_threshhold_sorted.index.to_list(), rotation=90)\n",
    "ax.bar_label(ax.containers[0], fmt='{0:.2f}')\n",
    "ax.set_title(\"feature correlations with the target\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The bigger an absolute value, the bigger its influence on the target.\n",
    "\n",
    "### Discussion\n",
    "In words this, data indicates for example that a lower age corresponds with higher chances of graduation similarly to how the posession of a scholarship does. This seems to make sense as younger students are known to be more likely to study full-time and as extraordinal grades are a key selection criteron for being awarded a scholarship. Grades and approved curricular units from both semester 1 and 2 seem to have the biggest influence on graduation, while on the other hand it is barely influenced by whether students study during daytime or in the evening."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Features With Each Other\n",
    "As highly correlated features do not add additional information to the model, aim for features that have a high correlation with the target but a low correlation amongst themselves.\n",
    "\n",
    "A high correlation between single features demonstrates a linear dependency. Highly correlated features have similar effects on the target and therefore do not necessarily add new information to the models when both present.\n",
    "\n",
    "Therefore, identify groups of highly correlated features and out of them, pick the one feature with the highest correlation with the target.\n",
    "\n",
    "First calculate the correlation matrix using only the features with a high correlation with the target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only use features highly correlated with the target\n",
    "df_corr_target = student_data_scaled[corr_feature_target_threshhold_sorted.index]\n",
    "\n",
    "# create the correlation matrix\n",
    "correlations_features = df_corr_target.corr()\n",
    "\n",
    "# round to two decimals\n",
    "correlations_features = correlations_features.round(2) \n",
    "\n",
    "correlations_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To increase reabability, keep only pairwise correlations above a pre-defined threshhold:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CORRELATION_TRESHHOLD = 0.4 # change as desired\n",
    "\n",
    "# remove correlations below the threshhold\n",
    "correlations_features_filtered = correlations_features[abs(correlations_features) > CORRELATION_TRESHHOLD]\n",
    "\n",
    "# round to two decimals\n",
    "correlations_features_filtered = correlations_features_filtered.round(2)\n",
    "\n",
    "correlations_features_filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=1, nrows=2, figsize=(15,20))\n",
    "\n",
    "whole = sns.heatmap(data=correlations_features, annot=True, linewidths=0.1, ax=ax[0])\n",
    "whole.set_title('all correlations')\n",
    "\n",
    "filtered = sns.heatmap(data=correlations_features_filtered, annot=True, linewidths=0.1, ax=ax[1])\n",
    "filtered.set_title('filtered correlations')\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion\n",
    "\n",
    "A good example for the logic behind correlations can be seem by the ``age at enrollment`` which is highly correlated with three other features, namely the ``application mode``, ``marital status`` and ``daytime/evening attendance``. Knowing that a lot of people marry between the age of 25 and 30, the positive correlation between the age and marital mode makes sense as it states that younger students are less likely to be married. Furthermore, younger students are more likely to be full-time students, while older students are more likely to study part-time next to their job and possibly family. Thus it makes sense that younger full-time students applied through the general contigent and mostly study during daytime.\n",
    "\n",
    "Another interesting correlation can be seen in ``debtor`` and ``tuition fees up to date``. One could for example argue, how students that forget to pay their tuition fees could also forget to pay back credits which would lead them into debt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Feature Selection\n",
    "\n",
    "Out of a group of pairwise correlated features, pick only the one feature which has the highest correlation with the target variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_drop = ['marital_status', 'application_mode', 'daytime_evening_attendance', 'previous_qualification', 'previous_qualification_grade', 'debtor', 'curricular_units_1st_sem_enrolled', 'curricular_units_1st_sem_approved', 'curricular_units_1st_sem_grade', 'curricular_units_1st_sem_without_evaluations' ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how the number of features got reduced from 36 to 11:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dataframe = df_corr_target.drop(columns=to_drop, axis='columns')\n",
    "\n",
    "final_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Data Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = final_dataframe.drop(columns='target')\n",
    "y = final_dataframe['target']\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "\n",
    "\n",
    "# Probabilistic Model\n",
    "probabilistic_model = GaussianNB()\n",
    "\n",
    "# Tree-based Model\n",
    "rfc = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Distance-Based Model\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "# Ensemble Methods\n",
    "gbc = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
    "xgbc = XGBClassifier(objective='multi:softmax', num_class=3, random_state=42)\n",
    "\n",
    "models = {\n",
    "    'Gaussian Naive Bayes': GaussianNB(),\n",
    "\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "\n",
    "    'K-Nearest Neighbors': KNeighborsClassifier(n_neighbors=5),\n",
    "\n",
    "    'Gradient Boosting': GradientBoostingClassifier(n_estimators=100, random_state=42),\n",
    "    'XGBoost': XGBClassifier(random_state=42)\n",
    "}\n",
    "\n",
    "# Specify the number of folds for K-fold cross-validation\n",
    "num_folds = 10\n",
    "\n",
    "# Create KFold objects\n",
    "folds = {\n",
    "    'K-Fold' : KFold(n_splits=num_folds, shuffle=True, random_state=42),\n",
    "    'Stratified K-Fold' : StratifiedKFold(n_splits=num_folds)\n",
    "}\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In scikit-learn, the KNeighborsClassifier expects the input data to be in the form of a NumPy array or array-like object, not a DataFrame.\n",
    "\n",
    "This is why we call \".values\" on our input data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Method to train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, model_name, X_train, y_train):\n",
    "    try:\n",
    "        # Train the model\n",
    "        model.fit(X_train.values, y_train.values)\n",
    "    except Exception as e:\n",
    "        print(f\"Error while training {model_name}: {e}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Method for cross validation prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def cross_validate_model(model, model_name, X, y, folding, fold_name):\n",
    "    try:\n",
    "        # Use cross_val_predict to get predictions for each fold\n",
    "        y_pred = cross_val_predict(model, X.values, y.values, cv=folding)\n",
    "\n",
    "        # Calculate confusion matrix\n",
    "        cm = confusion_matrix(y, y_pred)\n",
    "        #print(f\"Confusion Matrix with {fold_name}:\\n{cm}\")\n",
    "\n",
    "        # Calculate accuracy\n",
    "        accuracy = accuracy_score(y, y_pred)\n",
    "        print(f\"{fold_name} with method cross_val_predict and model: {model_name} - Accuracy: {accuracy:.2f}\\n\")\n",
    "\n",
    "        print(f\"Classification Report with cross-val-predict for {model_name} and {fold_name} folding:\\n\")\n",
    "        print(classification_report(y, y_pred) + \"\\n\")\n",
    "\n",
    "        return cm\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error while cross-validating {model_name}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Method to plot confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(model_name, cm_dict):\n",
    "\n",
    "    # Set the number of rows and columns for the subplots\n",
    "    num_rows = 1\n",
    "    num_cols = len(cm_dict)\n",
    "    \n",
    "    # Set the figure size\n",
    "    fig, axes = plt.subplots(num_rows, num_cols, figsize=(15, 5))\n",
    "\n",
    "    # Flatten the axes if only one row\n",
    "    axes = axes.flatten() if num_rows == 1 else axes\n",
    "\n",
    "    # Iterate through the dictionary items and create subplots\n",
    "    for idx, (title, matrix) in enumerate(cm_dict.items()):\n",
    "        ax = axes[idx]\n",
    "        sns.heatmap(matrix, annot=True, fmt='d', cmap='Blues', ax=ax)\n",
    "        ax.set_title(title)\n",
    "        ax.set_xlabel('Predicted')\n",
    "        ax.set_ylabel('Actual')\n",
    "\n",
    "    # Set the title for the entire plot\n",
    "    plt.suptitle(model_name)\n",
    "    \n",
    "    # Adjust layout\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Methode to get feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_feature_importance(model, X):\n",
    "    feature_importance = model.feature_importances_\n",
    "    feature_dict = dict(zip(X.columns, feature_importance))\n",
    "\n",
    "    # Sort the dictionary by values in ascending order\n",
    "    sorted_dict = dict(sorted(feature_dict.items(), key=lambda item: item[1], reverse=True))\n",
    "    print(sorted_dict)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Methode that does everything (fit, evaluate (cross-validation), feature importance, plot confusion matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "def train_and_evaluate_model(model, model_name, X, y, folding, fold_name):\n",
    "    try:\n",
    "        # Perform K-fold cross-validation and get accuracy scores for each fold\n",
    "        cv_scores = cross_val_score(model, X.values, y.values, cv=folding, scoring='accuracy')\n",
    "        print(f\"{fold_name} with method cross_val_score and model: {model_name} - Accuracy: {np.mean(cv_scores):.2f} (Â± {np.std(cv_scores):.2f})\\n\")\n",
    "\n",
    "        conf_mat = cross_validate_model(model, model_name, X, y, folding, fold_name)\n",
    "        \n",
    "        if conf_mat is not None:\n",
    "            # Check if the model has feature_importances_ attribute\n",
    "            if hasattr(model, 'feature_importances_'):\n",
    "                analyze_feature_importance(model, X)\n",
    "            else:\n",
    "                print(f\"Feature importance not available for {model_name} with {fold_name} folding.\" + \"\\n\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error while processing {model_name}: {e}\")\n",
    "        \n",
    "    return conf_mat"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execute everything for each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#TRAIN_FRACTION = 0.75\n",
    "#train = pd.concat([final_dataframe[final_dataframe['target'] == 0].sample(frac=TRAIN_FRACTION), final_dataframe[final_dataframe['target'] == 1].sample(frac=TRAIN_FRACTION),final_dataframe[final_dataframe['target'] == 2].sample(frac=TRAIN_FRACTION)])\n",
    "#test = final_dataframe.drop(train.index)\n",
    "#X_train = test.drop(columns='target')\n",
    "#y_train = test['target']\n",
    "#X_test = test.drop(columns='target')\n",
    "#y_test = test['target']\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTENC\n",
    "\n",
    "X = train_data.drop(columns='target')\n",
    "y = train_data['target']\n",
    "\n",
    "sm = SMOTENC(random_state=42, categorical_features=\"auto\")\n",
    "X_res, y_res = sm.fit_resample(X, y)\n",
    "y_res.shape\n",
    "\n",
    "X_test = test_data.drop(columns='target')\n",
    "y_test = test_data['target']\n",
    "#X = final_dataframe.drop(columns='target')\n",
    "#y = final_dataframe['target']\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X_res,y_res,test_size=0.2,random_state=42)\n",
    "\n",
    "X_train = train_data.drop(columns='target')\n",
    "y_train = train_data['target']\n",
    "# Loop through your models and call the train_and_evaluate_model method\n",
    "for model_name, model in models.items():\n",
    "    cm_dict = {}\n",
    "    # Train the model\n",
    "    train_model(model, model_name, X_train, y_train)\n",
    "\n",
    "    for fold_name, fold in folds.items():\n",
    "        cm_dict[fold_name] = train_and_evaluate_model(model, model_name, X_res, y_res, fold, fold_name)\n",
    "\n",
    "    # Plot confusion matrix using seaborn\n",
    "    plot_confusion_matrix(model_name, cm_dict)\n",
    "\n",
    "\n",
    "    # Predict for Test-data\n",
    "    y_pred = model.predict(X_test.values)\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Prediction of test set with model: {model_name} - Accuracy: {accuracy:.2f}\\n\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA, ein random feature nehmen, gini co efficient(rfc), multiple linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_practical",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
